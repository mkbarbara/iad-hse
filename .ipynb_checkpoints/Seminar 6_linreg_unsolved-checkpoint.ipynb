{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSHI7j-Q28j3"
   },
   "source": [
    "# Предобработка данных и функции потерь в линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96iNvJn-28j4"
   },
   "source": [
    "## Данные\n",
    "Для демонстраций загрузим набор данных [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/Automobile). В данных присутствуют категориальные, целочисленные и вещественнозначные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u30Ou_XY28j5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_raw = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\", \\\n",
    "                    header=None, na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "U3zLI-Jd28j8",
    "outputId": "84092f79-d9ca-489e-c062-3f80a5a9787c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1            2    3    4     5            6    7      8     9   ...  \\\n",
       "0   3    NaN  alfa-romero  gas  std   two  convertible  rwd  front  88.6  ...   \n",
       "1   3    NaN  alfa-romero  gas  std   two  convertible  rwd  front  88.6  ...   \n",
       "2   1    NaN  alfa-romero  gas  std   two    hatchback  rwd  front  94.5  ...   \n",
       "3   2  164.0         audi  gas  std  four        sedan  fwd  front  99.8  ...   \n",
       "4   2  164.0         audi  gas  std  four        sedan  4wd  front  99.4  ...   \n",
       "\n",
       "    16    17    18    19    20     21      22  23  24       25  \n",
       "0  130  mpfi  3.47  2.68   9.0  111.0  5000.0  21  27  13495.0  \n",
       "1  130  mpfi  3.47  2.68   9.0  111.0  5000.0  21  27  16500.0  \n",
       "2  152  mpfi  2.68  3.47   9.0  154.0  5000.0  19  26  16500.0  \n",
       "3  109  mpfi  3.19  3.40  10.0  102.0  5500.0  24  30  13950.0  \n",
       "4  136  mpfi  3.19  3.40   8.0  115.0  5500.0  18  22  17450.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xHXo8yny28j_"
   },
   "outputs": [],
   "source": [
    "y = X_raw[25]\n",
    "X_raw = X_raw.drop(25, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RLJ_PH928kC"
   },
   "source": [
    "## Предобработка данных\n",
    "\n",
    "Предобработка данных важна при применении любых методов машинного обучения, а в особенности для линейных моделей. В sklearn предобработку удобно делать с помощью различных модулей [preprocessing](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) или методов библиотеки pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OIYuChq28kH"
   },
   "source": [
    "### Заполнение пропусков\n",
    "В матрице объекты-признаки могут быть пропущенные значения, и это вызовет ошибку при попытке передать такую матрицу в функцию обучения модели или даже предобработки. Если пропусков немного, можно удалить объекты с пропусками из обучающей выборки. Заполнить пропуски можно разными способами:\n",
    "* заполнить средними (mean, median);\n",
    "* предсказывать пропущенные значения по непропущенным.\n",
    "\n",
    "Часто используют первый вариант - он проще. Для заполнения константами можно использовать метод датафрейма `fillna`, для замены средними - класс `impute.SimpleImputer` (в более старых версиях `scikit-learn` - `preprocessing.Imputer`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-mqpQ46y4If",
    "outputId": "b84a8dea-b703-4b35-bdb6-5d25bb1798db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jt8GLu6ly4If",
    "outputId": "03ca79b2-53a4-4501-f7f6-9517c75fc6e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1     41\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      2\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     4\n",
       "19     4\n",
       "20     0\n",
       "21     2\n",
       "22     2\n",
       "23     0\n",
       "24     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_8xF0_ruy4Ig"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_5bbvMK828kH"
   },
   "outputs": [],
   "source": [
    "# для удобства работы с нашим датасетом создаем маску, указывающую на столбцы с категориальными признаками\n",
    "cat_features_mask = (X_raw.dtypes == \"object\").values # категориальные признаки имеют тип \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjYtWWxQ28kK"
   },
   "outputs": [],
   "source": [
    "# для вещественнозначных признаков заполним пропуски средними\n",
    "X_real = X_raw[X_raw.columns[~cat_features_mask]]\n",
    "mis_replacer = SimpleImputer(strategy=\"mean\")\n",
    "X_no_mis_real = pd.DataFrame(data=mis_replacer.fit_transform(X_real), columns=X_real.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для категориальных - пустыми строками\n",
    "X_cat = X_raw[X_raw.columns[cat_features_mask]].fillna(\"\")\n",
    "X_no_mis = pd.concat([X_no_mis_real, X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "H34gZsTX28kN",
    "outputId": "e59fc36c-9131-4923-fbaa-d41941e265ea"
   },
   "outputs": [],
   "source": [
    "X_no_mis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joT6goKYy4Ih",
    "outputId": "792035e3-4863-4633-fc96-b893be4184e7"
   },
   "outputs": [],
   "source": [
    "X_no_mis.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNoCS3EK28kR"
   },
   "source": [
    "### Преобразование нечисловых признаков\n",
    "Как вы помните, большниство моделей машинного обучения требуют, чтобы на вход функции обучения подавалас матрица состоящая из вещественных чисел. В процессе обучения используются свойства вещественных чисел, в частности, возможность сравнения и применения арифметических операций. Поэтому, даже если формально в матрице объекты-признаки записаны числовые значения, нужно всегда анализировать, можно ли относиться к ним как к числам. \n",
    "\n",
    "__Пример:__ некоторые признаки могут задаваться целочисленными хешами или id (например, id пользователя соц. сети), однако нельзя сложить двух пользователей и получить третьего, исходя из их id (как это может сделать линейная модель).\n",
    "\n",
    "Напоминаем, что для обработки категориальных признаков, часто применяют [one-hot encoding](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) в результате чего, вместо одного признака добавится $K$ бинарных признаков - по одному на каждое возможное значение исходного признака. В `sklearn` это можно сделать с помощью классов `OneHotEncoder`, но проще использовать функцию `pd.get_dummies`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBmFt92528kS"
   },
   "source": [
    "Следует заметить, что в новой матрице будет очень много нулевых значений. Чтобы не хранить их в памяти, можно задать параметр `OneHotEncoder(sparse=True)` или `pd.get_dummies(sparse=True)`, и метод вернет [разреженную матрицу](http://docs.scipy.org/doc/scipy/reference/sparse.html), в которой хранятся только ненулевые значения. Выполнение некоторых операций с такой матрицей может быть неэффективным, однако большинство методов sklearn умеют работать с разреженными матрицами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZxxhNbj28kS"
   },
   "source": [
    "__Вопрос:__ стоит ли применять one-hot encoding для признаков с большим числом категорий (например, id)? Почему?\n",
    "\n",
    "__Вопрос:__ какая проблема возникнет при применении вышеописанного способа кодирования для обучения линейной регрессии?\n",
    "    \n",
    "Необходимо удалить один из столбцов, созданных для каждого признака. Для этого в get_dummies надо поставить drop_first=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqwMFEqt28ka",
    "outputId": "0f30bded-aedf-4b6a-e829-7d4b7b18624e"
   },
   "outputs": [],
   "source": [
    "X_no_mis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "hLiNNMYz28kc",
    "outputId": "71635d35-f724-43d8-9244-cb83af917b0a"
   },
   "outputs": [],
   "source": [
    "X_dum = pd.get_dummies(X_no_mis, drop_first=True)\n",
    "print(X_dum.shape)\n",
    "X_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVJEU31i28kf"
   },
   "source": [
    "Помимо категориальных, преобразования требуют, например, строковые признаки. Их можно превращать в матрицу частот слов [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), матрицу частот буквосочетаний фиксированной длины, можно извлекать другие признаки (например, длина строки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaZ_SxAP28kf"
   },
   "source": [
    "### Масштабирование признаков\n",
    "При начале работы с данными всегда рекомендуется приводить все признаки к одному масштабу.  Это важно по нескольким причинам:\n",
    "* ускорение обучения модели;\n",
    "* улучшение численной устойчивости при работе с матрицей объекты-признаки\n",
    "* для линейных моделей: интерпретация весов при признаках как меры их значимости\n",
    "\n",
    "[Полезная ссылка](https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLCmI77c28kg"
   },
   "source": [
    "Данные можно масштабировать по-разному:\n",
    "\n",
    "- Стандартизация - вычитание среднего из каждого признака и деление на стандартное отклонение (`StandardScaler` в `sklearn`).\n",
    "\n",
    "- Нормализация - вычитание минимума из каждого признака, а затем деление на разницу максимального и минимального значения (`MinMaxScaler` в `sklearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHFbmKRzy4Im"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNymKr5D28kh"
   },
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "X_real_norm_np = normalizer.fit_transform(X_dum)\n",
    "X = pd.DataFrame(data=X_real_norm_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "3kHPINOO28kk",
    "outputId": "be974402-62de-4387-dc04-6447b504bf92"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbwg7jRv28kn"
   },
   "source": [
    "### Добавление признаков\n",
    "Особенно важным моментом для линейной регрессии является нелинейное преобразование признаков. Это позволяет использовать линейную регрессию для моделирования нелинейных зависимостей. \n",
    "\n",
    "Наиболее популярны следующие преобразования: \n",
    "- полиномиальные признаки (PolynomialFeatures в sklearn)\n",
    "- взятие логарифма\n",
    "- квадратного корня\n",
    "- применение тригонометрических функий.\n",
    "\n",
    "Например, посмотрев на данные, мы можем заметить, что зависимость целевой переменной от шестого признака скорее квадратичная, чем линейная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSL1DWQw28ko"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Bv0qZAP028kr",
    "outputId": "c1fbdef3-0154-4870-d258-1b46177dc96d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[6], y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "In7bi4a728ku",
    "outputId": "d01a472e-d0e9-446a-f011-2944ef6fdb65"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[6]**2, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LLqJaxF28kw"
   },
   "source": [
    "> А для признака номер 13 линеаризовать зависимость получается с помощью функции $\\frac 1 {\\sqrt{x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Ff2MqK_U28kx",
    "outputId": "ca370ede-de10-4c7c-f0cb-5fdf1a7717c9"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[13], y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "6MhgQI3p28kz",
    "outputId": "444da03b-f69c-41f3-98d8-f96105777bc8"
   },
   "outputs": [],
   "source": [
    "plt.scatter(1 / np.sqrt(X[13]), y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6Qy8_i_28k1"
   },
   "source": [
    "__Обратите внимание__: при генерации полиномиальных признаков матрица объекты-признаки может занимать много памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPqAUdTR28k1"
   },
   "source": [
    "## Функции потерь в регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "4nkY6ylA28k2"
   },
   "source": [
    "Функционал качества в задачах обучения с учителем обычно задается в виде суммы по объектам выборки:\n",
    "$$Q(a) = \\frac 1 \\ell \\sum_{i=1}^\\ell L(y_i, a(x_i)),$$\n",
    "где $L(\\cdot, \\cdot)$ - функция потерь, задающая штраф за разницу между предсказанием и истинным значением целевого признака. Свойства функции потерь:\n",
    "* $L(y_i, a(x_i)) \\geqslant 0$;\n",
    "* $L(y_i, y_i) = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tvTz0GJ28k3"
   },
   "source": [
    "Функционал качества должен в первую очередь отвечать требованиям заказчика, при этом математические свойства функции потерь могут быть неудобны для оптимизации. \n",
    "\n",
    "__Пример:__ если мы не различаем маленькие ошибки (между 0.01 и 0.1 нет особой разницы), но зато не хотим получать большие ошибки, можно использовать следующую функцию потерь:\n",
    "\n",
    "$$L(y_i, a(x_i)) = [| y_i - a(x_i) | < \\varepsilon],$$ $\\varepsilon$ - допустимая разница между предсказанием и фактом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ade-VU28k4"
   },
   "source": [
    "### Среднеквадратичная и средняя абсолютная ошибка\n",
    "Кроме требований заказчика, функционал качества должен учитывать математические особенности модели - например, устойчивость к шумовым объектам. \n",
    "\n",
    "В линейной регрессии Mean Squared Error: $L(y_i, a(x_i)) = (a(x_i) - y_i)^2$ не обладает этим свойством, потому что задает очень большие штрафы за большие отклонения от фактического значения. \n",
    "\n",
    "$$MSE (a, X, Y) = \\sum^L_{i=1}(a(x_i) - y_i)^2$$\n",
    "\n",
    "Рассмотрим это явление на примере. Выберем один признак, от которого целевой признак (имеющий индекс 15 в матрице X) зависит практически линейно. Добавим к выборке два объекта-выброса и посмотрим, как изменится оптимизированная на MSE прямая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPjI7SgJ28k5"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVmJjuUU28k7"
   },
   "outputs": [],
   "source": [
    "X_subset = X[[7, 15]].values\n",
    "X_subset_modified = np.vstack((X_subset, [[1, 90], [2, 50]])) # добавление двух шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNZJOsJp28k9"
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MSE(X_subset):\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])   # визуализируем точки\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_subset[:, 0][:, np.newaxis], X_subset[:, 1])  # вычислим веса линейной модели\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    line = lr.predict(grid[:, np.newaxis])\n",
    "    plt.plot(grid, line)   # визуализируем прямую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "EurNOGcA28k_",
    "outputId": "a0a4b098-838b-4f81-9796-b6fb5f1d80eb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter_points_and_plot_line_MSE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter_points_and_plot_line_MSE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6JR5Gxq8ZcZ"
   },
   "source": [
    "**Задание:** Реализуйте функцию для подсчета MSE с использованием numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1mp3T5y844J",
    "outputId": "8bec51dd-6f89-4b1a-9653-9964ca0e4c34"
   },
   "outputs": [],
   "source": [
    "def MSE(y: np.array, y_pred: np.array):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "\n",
    "a = np.array([11,20,19,17,10])\n",
    "pred = np.array([12,18,19.5,18,9])\n",
    "mse = MSE(y=a, y_pred=pred)\n",
    "print(\"The Mean Square Error is: \" , mse)\n",
    "assert mse == 1.45 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoNn7V3VAxH7"
   },
   "source": [
    "Среднеквадратичная ошибка подходит для сравнения двух моделей или для контроля качества во время обучения. Из-за того, разница возводится в квадрат - сложно дать этому числу интерпретацию. Для лучшей интерпретации используется Root Mean Square Error (RMSE). Таким образом, если MSE показывает разницу в квадратных единицах, значение RMSE сохранится в исходных. \n",
    "\n",
    "$$RMSE (a, X, Y) = \\sqrt{MSE (a, X)} = \\sqrt{ \\sum^L_{i=1}(a(x_i) - y_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2R6urCMCeN5"
   },
   "source": [
    "**Задание:** Реализуйте функцию для подсчета RMSE с использованием numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IowhU6p1Cj47",
    "outputId": "4c63cf61-4097-4488-f889-8a8c8eb777c6"
   },
   "outputs": [],
   "source": [
    "def RMSE(y, y_pred):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "\n",
    "rmse = RMSE(y=a, y_pred=pred)\n",
    "print(\"The Root Mean Square Error is: \" , rmse)\n",
    "assert rmse == 1.2041594578792296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3eqYonVJd8a"
   },
   "source": [
    "Коэффициент детерминации $R^2$ показывает долю дисперсии в целевой переменной, которая обьяснена зависимыми переменными. $R^2$ можно интерпретировать как некоторого рода нормированное MSE.\n",
    "\n",
    "$$R^2(a, X, Y) = 1 - \\frac {\\sum^L_{i=1}(a(x_i) - y_i)^2}{\\sum^L_{i=1}(y_i - \\bar{y})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgfsEt5DLbQW"
   },
   "source": [
    "**Задание:** реализуйте функцию для вычисления $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KK3o7GozLjkV"
   },
   "outputs": [],
   "source": [
    "def R_squared(y, y_pred):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "r_squared = R_squared(y=a, y_pred=pred)\n",
    "print('The R2 is:', r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7c8WRk28lC"
   },
   "source": [
    "Из-за того, что мы учитываем квадрат отклонения - шумовые объекты могут сильно изменить наклон прямой. Поэтому в качестве альтернативы MSE можно использовать Mean Absolute Error: $L(y_i, a(x_i)) = |a(x_i) - y_i|$.\n",
    "\n",
    "$$MAE(a, X, Y) = \\frac {1}{L} \\sum^L_{i=1}|a(x_i) - y_i|$$\n",
    "\n",
    "Теперь обучим регрессию, оптимизируя MAE. В `sklearn` такая регрессия не реализована, но можно использовать модуль `statsmodels` - более формально, необходимая модель может быть получена с помощью обучения квантильной регрессии с параметром `q=0.5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jqHvxqXDt6q"
   },
   "source": [
    "**Задание:** Реализуйте функцию для подсчета MAE с использованием numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eo-0TW82DzPw",
    "outputId": "f4e36fd7-9184-4ebb-e7f6-79e48d5c9124"
   },
   "outputs": [],
   "source": [
    "def MAE(y, y_pred):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "\n",
    "mae = MAE(y=a, y_pred=pred)\n",
    "print(\"The Mean Absolute Error is: \" , mae)\n",
    "assert mae == 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KRvgVyVy4Iq"
   },
   "source": [
    "!pip install --user git+https://github.com/statsmodels/statsmodels # (если не работает импортирование библиотек ниже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PL2zqH8x28lD"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFTTYeqY28lF"
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MAE(X_subset):\n",
    "    # задаем зависимость переменной f15 от переменной f7 и передаем данные\n",
    "    mod = smf.quantreg('f15 ~ f7', pd.DataFrame(data=X_subset, columns=[\"f7\", \"f15\"]))\n",
    "    res = mod.fit(q=0.5)\n",
    "    \n",
    "    # визуализируем точки\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    \n",
    "    # визуализируем прямую\n",
    "    plt.plot(grid, grid * res.params[\"f7\"] + res.params[\"Intercept\"])\n",
    "    return mod, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ie_4TNdc28lH",
    "outputId": "85bcab8b-0876-4f52-98a7-87dc18beecdd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWlsyGfu28lK"
   },
   "source": [
    "Прямая практически не изменила направление из-за выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2doEVqJ28lL"
   },
   "source": [
    "Попробуем добавить больше шумовых объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdDGJBER28lM"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "X_subset_modified_twice = np.vstack((X_subset_modified, np.random.randint(5, size=60).reshape(-1, 2)*[1, 30])) # добавление 30 шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "McWJOOlN28lO",
    "outputId": "c44d54b7-7cda-4650-cf53-257573a82815"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified_twice)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCq7zu_K28lQ"
   },
   "source": [
    "Под таким количеством выбросов, изменилась даже регрессия над MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PMB5CGj28lR"
   },
   "source": [
    "Рассмотрим некоторые свойства MSE и MAE.\n",
    "\n",
    "Допустим алгоритм возвращает константное предсказание: $a(x) = C, C \\in R$. В качестве примера такого алгоритма можно представить предсказание прибыли в январе константой, равной средней прибыли за январь всех предыдущих лет работы.\n",
    "\n",
    "__Задача.__ Найдите $C$, минимизирующий среднеквадратичную ошибку.\n",
    "\n",
    "__Задача.__ Найдите $C$, минимизирующий среднюю абсолютную ошибку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7lxcAGx28lR"
   },
   "source": [
    "Поскольку средняя абсолютная ошибка не является дифференцируемой по $w$ функцией, оптимизировать ее напрямую методом градиентного спуска не удастся. Для этого используются [субградиентные](https://ru.wikipedia.org/wiki/Субдифференциал) (что в почти не меняет процедуры спуска, только вместо градиента берется один из субградиентов) или другие методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMkNLdXE28lS"
   },
   "source": [
    "### Huber Loss\n",
    "Иногда используют \"гибрид\" MAE и MSE, который, как и MAE, устойчив к шумовым объектам, и как и MSE, мало штрафует малые отклонения от фактического значения целевого признака - Huber Loss:\n",
    "$$L_i(y_i, a(x_i)) = \\phi_\\varepsilon(a(x_i) - y_i)$$\n",
    "$$\\phi_\\varepsilon(z) = \\begin{cases} \\frac 1 2 z^2, - \\varepsilon < z < \\varepsilon, \\\\\\varepsilon (|z| - \\frac 1 2 \\varepsilon), иначе \\\\ \\end{cases}$$\n",
    "\n",
    "Можно проверить, что у этой функции существует непрерывная первая проиводная во всех точках.\n",
    "\n",
    "Оптимизация Huber Loss реализована в sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63HdJ0fl28lT"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5_lQyA1Hz2l"
   },
   "source": [
    "**Задание:** реализуйте функцию потерь Хьюбера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyTaEVslFGb5",
    "outputId": "9223c84d-8e2a-438e-c0bd-35aa797dd8e7"
   },
   "outputs": [],
   "source": [
    "def Huber(y, y_pred):\n",
    "    #YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "huber = Huber(y=a, y_pred=pred)\n",
    "print(\"The Huber Loss is:\", huber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00WIecdEGqE7"
   },
   "source": [
    "### Mean Squared Logarifmic Erorr (MSLE)\n",
    "\n",
    "Данная функция потерь применяется в случаях, когда лучше получать заниженные прогнозы, нежели завышенные.\n",
    "\n",
    "Важное примечание: из-за присутствия логарифма в формуле **целевая переменная должна быть неотрицательной!**. Единицу добавляем, чтобы случайно не получить логарифм нуля.\n",
    "\n",
    "$$L_i(a, X_i, Y_i) = (\\log(a(x_i)+1) - \\log(y_i+1))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDbvxTRyHyRB"
   },
   "source": [
    "**Задание:** реализуйте MSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzpzqKvLINLo"
   },
   "outputs": [],
   "source": [
    "def MSLE(y, y_pred):\n",
    "    #YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "msle = MSLE(y=a, y_pred=pred)\n",
    "print(\"The Mean Squared Logarifmic Error is:\", msle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5Yy3Ze228lV"
   },
   "source": [
    "### Quantile Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vBaAgJJ28lW"
   },
   "source": [
    "В некоторых задачах штраф за ошибку зависит не только от величины абсолютного отклонения от фактического значения, но и от знака этого отклонения. Например, лучше предсказать спрос больше, чем будет по факту, чем меньше, потому что во втором случае будет потеряна прибыль. В этом случае используется квантильная регрессия со следующей функцией потерь:\n",
    "$$L_i(y_i, a(x_i)) = \\rho_\\tau(y_i - x_i^T w),$$\n",
    "$$\\rho_\\tau(z) = \\begin{cases} \\tau z, \\quad z > 0, \\\\ (\\tau - 1) z, \\quad z \\leqslant 0 \\end{cases}$$\n",
    "Параметр $\\tau \\in (0, 1)$ влияет на то, насколько различаются штрафы за положительную и отрицательную разницу.\n",
    "\n",
    "Изобразим график квантильной функции потерь вместе с некоторыми другими рассмотренными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "LZvF9yTL28lW",
    "outputId": "124dc493-7f6c-486d-9adf-2379c3d2ef6e"
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(-3, 3, 100)\n",
    "quantile_tau = 0.2\n",
    "mse_loss = grid ** 2\n",
    "rmse_loss = np.sqrt(mse_loss)\n",
    "mae_loss = np.abs(grid)\n",
    "huber_loss = 0.5 * mse_loss * (grid >= -1) * (grid <= 1) + (mae_loss - 0.5) * (grid < -1) + (mae_loss - 0.5)  * (grid > 1)\n",
    "quantile_loss = quantile_tau * grid * (grid > 0) + (quantile_tau - 1) * grid * (grid <= 0)\n",
    "plt.plot(grid, mae_loss, label=\"Absolute Loss\")\n",
    "plt.plot(grid, mse_loss, label=\"Quadratic Loss\")\n",
    "plt.plot(grid, rmse_loss, label=\"Root Quadratic Loss\")\n",
    "plt.plot(grid, huber_loss, label=\"Huber Loss\")\n",
    "plt.plot(grid, quantile_loss, label=\"Quantile Loss\")\n",
    "plt.xlabel(\"$y_i - a(x_i)$\")\n",
    "plt.ylabel(\"$L(y_i, a(x_i))$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKsQQ-I728lY"
   },
   "source": [
    "__Задача.__ Укажите параметр $\\tau$, при котором обучение квантильной регрессии равносильно оптимизации MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0dnqaQa28lZ"
   },
   "source": [
    "Проследим наклон прямой в нашей одномерной задаче регрессии при изменении $\\tau$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "rq4LwwR728lZ",
    "outputId": "09855fa8-123a-48cd-dc8b-6daf9f82c64e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[7], y)\n",
    "\n",
    "grid = np.linspace(0, 2, 100)\n",
    "dat = pd.DataFrame({\"x\":X[7], \"y\":y})\n",
    "mod = smf.quantreg('y ~ x', dat)\n",
    "\n",
    "for q in np.arange(0.1, 1, 0.1):\n",
    "    res = mod.fit(q=q)\n",
    "    plt.plot(grid, grid * res.params[\"x\"] + res.params[\"Intercept\"], linewidth=0.5, label=\"q = \"+str(q))\n",
    "\n",
    "plt.legend(loc=(1.1, 0.1))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aefAEVx7OiAR"
   },
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2jmXcciOl-K"
   },
   "source": [
    "Мы поработаем с данными о сообществах в США. Описание датасета:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/communities+and+crime\n",
    "\n",
    "Датасет на кэггле (в формате .csv):\n",
    "\n",
    "https://www.kaggle.com/kkanda/communities%20and%20crime%20unnormalized%20data%20set\n",
    "\n",
    "Будем предсказывать количество насильственных преступлений относительно численности населения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3lmXNVFOx0G"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRft8CJyO1z8"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('crimedata.csv', na_values=[\"?\"])\n",
    "\n",
    "# оставим лишь нужные колонки\n",
    "requiredColumns = [5, 6] + list(range(11,26)) + list(range(32, 103)) + [145]\n",
    "data = data[data.columns[requiredColumns]]\n",
    "\n",
    "# некоторые значения целевой переменной пропущены\n",
    "X = data.loc[data['ViolentCrimesPerPop'].notnull(), :].drop('ViolentCrimesPerPop', axis=1)\n",
    "y = data['ViolentCrimesPerPop'][X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCxXAdVtOiw4"
   },
   "source": [
    "### 1 Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw3DZ8zzPRuB"
   },
   "source": [
    "Обучим линейную регрессию и выведем качество по метрике MSE на обучающей и тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntYfZTzkQRAC"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test))))\n",
    "\n",
    "# Выведите ниже качество на обучении и тесте, рассчитаное с использованием функции\n",
    "# MSE(), написанной вами ранее\n",
    "# Сравните результаты\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd44Omp9TtcU"
   },
   "source": [
    "Популярным решением для регрессионных моделей является **регуляризация**.\n",
    "\n",
    "Во время оптимизации линейной регрессии, веса при переменных могут получится большими в абсолютных значениях. Это не очень хорошо, поскольку классификатор будет чувствителен к крайне маленьким изменениям в признаках объекта, а значит, переобучен.\n",
    "\n",
    "Для решения проблемы к функционалу ошибки добавляют так называемсый регуляризатор, который \"штрафует\" модель за слишком большую норму вектора весов:\n",
    "\n",
    "\n",
    "$$Q\\alpha(w) = Q(w) + \\alpha R(w)$$ \n",
    "\n",
    "где $R(w)$ - регуляризатор\n",
    "\n",
    "Наиболее распространенными являются L1 и L2 регуляризаторы\n",
    "$$L1: R(w) = ||w||_1 = \\sum^d_i w_i^2$$\n",
    "\n",
    "$$L2: R(w) = ||w||_2 = \\sum^d_i |w_i|$$\n",
    "\n",
    "Давайте применим каждый из них к нашей задаче и посмотрим на изменение в результатах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-Lpzpe0QcJF"
   },
   "source": [
    "В качестве метода регуляризации используем Ridge ($L_2$-регуляризация)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RT8QZldbPqFr",
    "outputId": "126eb557-1c3d-4bdb-fe05-a4eb0adc1d76"
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzcwQ0T5QkRJ"
   },
   "source": [
    "### 2 Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjOT_WBfQnWX"
   },
   "source": [
    "Попробуем MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zedtNiBBQhOl"
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(data=sc.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(data=sc.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrldySniQ6jR"
   },
   "source": [
    "**Задание:** Напишите код обучения линейной регресии на масштабированных признаках и выведите ошибку на обучающей и валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyoESXkkRQA1"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkbwYrUdRSYR"
   },
   "source": [
    "**Задание:** проделайте аналогичную работу, добавив Ridge регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDELVx5FRh1F"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK7GsUVORnbG"
   },
   "source": [
    "### 3. High/low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1Obs0jBRpsw"
   },
   "source": [
    "Полезны ли признаки, имеющие высокую дисперсию? А низкую?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDlYyvBsRnwb",
    "outputId": "99a5078b-8d5c-4079-b130-c096ac8c41d4"
   },
   "outputs": [],
   "source": [
    "features_variance = X_train_scaled.var().sort_values(ascending=False)\n",
    "features_variance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qW04UvAbRyhG"
   },
   "source": [
    "Попробуем удалить признаки с самой низкой дисперсией и посмотреть, как изменится качество. В sklearn есть специальный инструмент для такого наивного отбора признаков. Стоит ли нормализовать перед этим признаки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StGlZfbeRsec",
    "outputId": "ef18c63f-14c6-4d84-98f7-ccc92e707dbe"
   },
   "outputs": [],
   "source": [
    "# можно убрать все признаки, дисперсия которых меньше заданного значения\n",
    "vs_transformer = VarianceThreshold(0.01)\n",
    "\n",
    "X_train_var = pd.DataFrame(data=vs_transformer.fit_transform(X_train_scaled), columns=X_train_scaled.columns[vs_transformer.get_support()])\n",
    "X_test_var = pd.DataFrame(data=vs_transformer.transform(X_test_scaled), columns=X_test_scaled.columns[vs_transformer.get_support()])\n",
    "\n",
    "X_train_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z60-yCrwR2rG",
    "outputId": "b4294aec-3712-41f5-8170-f924cfcd155b"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_var,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_var))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_var))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXlTH65eR5hs",
    "outputId": "5c6ce1a9-aa30-4b95-86fd-0ecda5f9791e"
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_var,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_var))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-tIhMytR9KO"
   },
   "source": [
    "### 4 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmyRffiqR9lz"
   },
   "source": [
    "Можно выбрать k признаков, которые дают наиболее высокие значения корреляции с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxgWrpvVR7_H"
   },
   "outputs": [],
   "source": [
    "# Выбираем 15 лучших признаков\n",
    "sb = SelectKBest(f_regression, k=15)\n",
    "\n",
    "X_train_kbest = pd.DataFrame(data=sb.fit_transform(X_train_var, y_train), columns=X_train_var.columns[sb.get_support()])\n",
    "X_test_kbest = pd.DataFrame(data=sb.transform(X_test_var), columns=X_test_var.columns[sb.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05_0s6Y0SPYp",
    "outputId": "4d2beea0-bc84-42ad-f239-3002fb223ef9"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_kbest,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_kbest))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_kbest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brBAuwBHSSXA",
    "outputId": "3ea8e8b3-4be0-4071-9a42-50453af4d5bc"
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_kbest,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_kbest))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_kbest))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1oWr6MASWck"
   },
   "source": [
    "А можно выбрать самые значимые признаки с точки зрения регрессии с $L_1$-регуляризацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R7rsWRvSVFA",
    "outputId": "be80b01d-4ccb-4231-8f99-c36459d30215"
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(5.0)\n",
    "l1_select = SelectFromModel(lasso)\n",
    "\n",
    "X_train_l1 = pd.DataFrame(data=l1_select.fit_transform(X_train_var, y_train), columns=X_train_var.columns[l1_select.get_support()])\n",
    "X_test_l1 = pd.DataFrame(data=l1_select.transform(X_test_var), columns=X_test_var.columns[l1_select.get_support()])\n",
    "\n",
    "X_train_l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VO2rVJfSikj",
    "outputId": "c2194e3b-8341-40cf-c0cd-a9616df38c72"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_l1,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_l1))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_l1))))\n",
    "\n",
    "ridge = Ridge(5.0).fit(X_train_l1,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_l1))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_l1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlvrsWnsSqJ2"
   },
   "source": [
    "### 5 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vD3_WwmwSspu"
   },
   "source": [
    "А можно сделать все вышеописанное сразу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6SHSnsUSpJU",
    "outputId": "ae41e7cd-bcdd-43b0-844e-b830c2b8821a"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('variance', VarianceThreshold(0.01)),\n",
    "    ('selection', SelectFromModel(Lasso(5.0))),\n",
    "    ('regressor', Ridge(5.0))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R84AM0WISw1i",
    "outputId": "7ab81bbe-a396-4eed-bb17-01db96062e6e"
   },
   "outputs": [],
   "source": [
    "print (\"Train: {}\".format(mean_squared_error(y_train, pipe.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, pipe.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN1m9tlWS2zh"
   },
   "source": [
    "Можно также настраивать параметры с помощью `GridSearch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fqn1f7qS2Kt",
    "outputId": "b07efc95-76ec-4699-dda9-9b80a2293f9d"
   },
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4m5LRWZgS_3e",
    "outputId": "7772273e-c44b-4298-e513-abd490a91ac4"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'variance__threshold': [0.005, 0.0075, 0.009, 0.01, 0.011, 0.012],\n",
    "    'selection__estimator__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "    'regressor__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0]\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, param_grid, iid=False, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G98XFUynTGJV",
    "outputId": "052f7b76-a35a-4c9d-83f2-19b69f9b1267"
   },
   "outputs": [],
   "source": [
    "pipe_best = grid_search.best_estimator_\n",
    "pipe_best.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Uhgfp_WTJvD",
    "outputId": "4206a94b-01cb-4429-ed67-6f57ed016262"
   },
   "outputs": [],
   "source": [
    "pipe_best.fit(X_train, y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, pipe_best.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, pipe_best.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0ir6jSdUGfc"
   },
   "source": [
    "### Источники\n",
    "[Лекции Евгения Соколова в рамках курса МО-1](https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/lecture-notes/)\n",
    "\n",
    "[Семинар Евгения Ковалева в рамках данного курса в 2019 году](https://github.com/KovalevEvgeny/minor2019-iad2/blob/master/sem05_linreg/sem05_linear_regression.ipynb)\n",
    "\n",
    "[Семинар Евгения Ковалева в рамках данного курса в 2020 году](https://github.com/KovalevEvgeny/minor2020-iad4/blob/master/sem06_linreg/sem06_linreg.ipynb)\n",
    "\n",
    "[Семинар Евгения Ковалева, посвященный отбору признаков и регуляризации (2020)](https://github.com/KovalevEvgeny/minor2019-iad2/tree/master/sem06_feature_selection_regularization)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "sem06_linreg_unsolved.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
